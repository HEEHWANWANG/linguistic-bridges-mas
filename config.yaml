# Linguistic Bridges Multi-Agent System Configuration
# Note: Most settings can be overridden via environment variables (.env file)
# See .env.template for all available options

project:
  name: "Linguistic Bridges"
  description: "Modeling Visual Art and Music Alignment through Language"
  version: "1.0.0"

# API Keys (set via environment variables)
# Models and parameters can be overridden via DEFAULT_MODEL, MAX_TOKENS, TEMPERATURE env vars
apis:
  anthropic:
    model: "claude-sonnet-4-5-20250929"  # Overridden by DEFAULT_MODEL env var
    max_tokens: 8000  # Overridden by MAX_TOKENS env var
    temperature: 0.7  # Overridden by TEMPERATURE env var
  
  google:
    model: "gemini-2.0-flash-001"  # Overridden by DEFAULT_MODEL env var
    temperature: 0.7  # Overridden by TEMPERATURE env var
  
  search:
    provider: "tavily"  # or "google"
  
  arxiv:
    max_results: 10
  
  diffusion:
    provider: "stability"  # or "dalle"
    model: "stable-diffusion-xl"

# Vector Database (path can be overridden via VECTOR_DB_PATH env var)
vector_db:
  provider: "chroma"  # or "faiss", "pinecone"
  collection: "linguistic_bridges_memory"
  embedding_model: "sentence-transformers/all-mpnet-base-v2"
  persist_directory: "./data/vector_db"  # Overridden by VECTOR_DB_PATH env var

# Agent Settings (can be overridden via environment variables)
agents:
  supervisor:
    max_iterations: 100
    progress_check_interval: 300  # Overridden by PROGRESS_CHECK_INTERVAL env var
    conflict_resolution_enabled: true
    max_parallel_agents: 10  # Overridden by MAX_PARALLEL_AGENTS env var
  
  research_guild:
    hypothesis:
      generation_batch_size: 7  # Overridden by HYPOTHESIS_GENERATION_COUNT env var
      evolution_rounds: 3  # Overridden by MAX_EVOLUTION_ITERATIONS env var
      ranking_method: "elo_tournament"
    meta_review:
      analysis_frequency: 10  # every N hypotheses
  
  forge_guild:
    experimental_loop:
      max_retries: 3
      feedback_threshold: 0.7  # correlation threshold to trigger re-evaluation
    code_review:
      auto_approve_threshold: 0.9
  
  chroniclers_guild:
    output_format: "latex"  # or "markdown", "docx"
    citation_style: "apa"

# Human-in-the-Loop Settings (timeout overridden by HUMAN_APPROVAL_TIMEOUT env var)
human_approval:
  required_for:
    - "finalize_hypothesis"
    - "deploy_experiment"
    - "major_code_changes"
  timeout: 3600  # Overridden by HUMAN_APPROVAL_TIMEOUT env var (0 = no timeout)

# Logging (DEBUG_MODE env var controls level)
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR (set via DEBUG_MODE=true for DEBUG)
  log_dir: "./logs"
  rotation: "1 day"

# Failure Recovery (overridden by MAX_RETRIES, RETRY_BACKOFF_FACTOR, GRACEFUL_DEGRADATION env vars)
failure_recovery:
  max_retries: 3  # Overridden by MAX_RETRIES env var
  backoff_factor: 2  # Overridden by RETRY_BACKOFF_FACTOR env var
  fallback_agents_enabled: true
  graceful_degradation: true  # Overridden by GRACEFUL_DEGRADATION env var

# Datasets
datasets:
  artemis:
    path: "./data/artemis"
    url: "https://www.artemisdataset.org/"
  sdd:
    path: "./data/sdd"
    url: "https://github.com/mulab-mir/song-describer-dataset"

# Experimental Settings
experiments:
  gpu_memory_limit: "16GB"
  max_experiment_time: 86400  # 24 hours in seconds
  checkpoint_frequency: 3600  # seconds
