# Linguistic Bridges Multi-Agent System - Environment Variables

# ============================================================================
# API Keys
# ============================================================================

# Required: Anthropic API Key for Claude
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Optional: Google AI API Key for Gemini
GOOGLE_API_KEY=your_google_api_key_here

# Optional: Tavily API Key for web search
TAVILY_API_KEY=your_tavily_api_key_here

# Optional: Stability AI API Key for image generation
STABILITY_API_KEY=your_stability_api_key_here

# Optional: HuggingFace API Key for model downloads
HUGGINGFACE_TOKEN=your_huggingface_token_here

# ============================================================================
# GitHub Configuration (for Version Control Agent)
# ============================================================================

# GitHub Personal Access Token (for repository operations)
# Get it from: https://github.com/settings/tokens
GITHUB_TOKEN=your_github_token_here

# Your GitHub username
GITHUB_USERNAME=your_github_username

# Default repository for version control (format: username/repo_name)
GITHUB_DEFAULT_REPO=your_username/your_repo_name

# Git user configuration
GIT_USER_NAME=Your Name
GIT_USER_EMAIL=your.email@example.com

# Git behavior settings
GIT_AUTO_COMMIT=true  # Automatically commit changes
GIT_AUTO_PUSH=false   # Automatically push to remote (requires approval if false)
GIT_BRANCH_PREFIX=linguistic-bridges  # Prefix for feature branches
GIT_COMMIT_MESSAGE_TEMPLATE=[{agent}] {action}: {description}  # Commit message format

# ============================================================================
# System Configuration
# ============================================================================

# Maximum number of agents that can run concurrently
MAX_PARALLEL_AGENTS=10

# Default LLM model to use (options: claude-sonnet-4-5, claude-opus-4, gemini-2.0-flash)
DEFAULT_MODEL=claude-sonnet-4-5

# Workspace directory for agent operations
WORKSPACE_PATH=.claude/workspace

# Maximum number of hypothesis evolution iterations
MAX_EVOLUTION_ITERATIONS=3

# Number of hypotheses to generate in each batch
HYPOTHESIS_GENERATION_COUNT=7

# Maximum tokens per LLM request
MAX_TOKENS=8000

# Temperature for LLM generation (0.0-1.0)
TEMPERATURE=0.7

# Timeout for human approval (seconds, 0 for no timeout)
HUMAN_APPROVAL_TIMEOUT=3600

# Enable debug logging (true/false)
DEBUG_MODE=false

# Progress check interval (seconds)
PROGRESS_CHECK_INTERVAL=300

# Maximum retries for failed operations
MAX_RETRIES=3

# Backoff factor for retry delays
RETRY_BACKOFF_FACTOR=2

# Vector database persistence directory
VECTOR_DB_PATH=./data/vector_db

# Enable graceful degradation on failures (true/false)
GRACEFUL_DEGRADATION=true
